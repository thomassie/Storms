---
title: "Storm data preparation"
author: "Thomas M. Massie"
date: "1/8/2018"
output: 
  html_document: 
    keep_md: true
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r include = FALSE}
rm(list=ls())
```


```{r include = FALSE}
# Load libraries.
library(repmis)
library(RCurl)
library(tidyverse)
library(ggplot2)
library(ggExtra)
library(lubridate)
library(scales)
library(chron)
library(ggmap)
library(sp)
library(leaflet)
library(maps)
library(maptools)
library(RColorBrewer)
```




## Loading the data

I downloaded the data sets from NOAA's [National Hurricane Center](http://www.nhc.noaa.gov/data/#hurdat), one for hurricanes and one for typhoons, and stored them in my respective GitHub repository. Data format is the revised Atlantic hurricane database (HURDAT2, see [here](http://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html) for details).  
Now, to start I will load both data sets from my repository, and add a variable that indicates the respective ocean it belongs to.
```{r echo = TRUE, message = FALSE}
dd.atlantic <- read_csv("https://raw.githubusercontent.com/thomassie/Storms/master/Data/atlantic.csv?token=AFYWCm0CTFVvcnJCMs2F3z0u0Ce_ditGks5aXIiEwA%3D%3D") %>%
  mutate(Ocean = "atlantic")
dd.pacific  <- read_csv("https://raw.githubusercontent.com/thomassie/Storms/master/Data/pacific.csv?token=AFYWCuigbUpPM8d8V93uIzgYr-aat70Eks5aXIlcwA%3D%3D") %>%
  mutate(Ocean = "pacific")
```

This is what the original Atlantic data looks like:
```{r echo = FALSE}
str(dd.atlantic)
```

...and the data from the Pacific:
```{r echo = FALSE}
str(dd.pacific)
```

I combine both data sets to a single one, and remove spaces in variable names by '.'.
```{r}
dd.org <- bind_rows(dd.atlantic, dd.pacific)
names(dd.org) <- make.names(names(dd.org), unique=TRUE)
str(dd.org)
```



## Data wrangling

Next, I make some adjustments but leave the original variables as they were (for comparison): 

- One important step is making new date, time, and datetime variables. 
- Also, wind speed is converted into the metric system (km per hour). 
- Further, I included a variable named 'Duration' which will come into play at a latter point when the duration of a storm is calculated. 
- And last, there are some inconsistencies in the data: Generally, when there is no data availabe for pressure cells were filled with '-999'. However, sometimes it is '-99' or odd entries. To make it homogeneous and to avoid trouble when using the values in calculation, I changed all these entries to 'NA'.
```{r}
dd <- dd.org %>%
  mutate(Date.new = as.Date(as.character(Date), "%Y%m%d")) %>%
  mutate(Time.new = times(sub("(.{2})", "\\1:", sprintf("%04d:00", Time)))) %>%
  # mutate(DateTime.new = with(dd.org, as.POSIXct(paste(Date.new, Time.new)))) %>%
  mutate(DateTime.new = with(dd.org, as.POSIXct(paste(Date.new, Time.new)))) %>%
  mutate(Year = year(DateTime.new)) %>%
  mutate(DateTime.sameyear = as.POSIXct(strptime(format(DateTime.new, "%m/%d %H:%M:%S"), "%m/%d %H:%M:%S"))) %>%
  mutate(Maximum.Wind.kph = round(Maximum.Wind * 1.609344, 0)) %>%
  mutate(ID.plus = paste(Name, " (",ID,")", sep = "")) %>%
  mutate(Duration = NA) %>%   # Needed at a latter point.
  # For some storms there's no data about wind speeds.
  # Hence, these are removed here.
  filter(Maximum.Wind >= 0) %>%
  mutate(Minimum.Pressure = ifelse(Minimum.Pressure > 500, Minimum.Pressure, NA))
# mutate(Minimum.Pressure = ifelse(Minimum.Pressure > 500, Minimum.Pressure, -999)) 
```

Then, for some variables it makes more sense if they are declared as factors.
```{r}
dd[c("ID", 
     "Year",
     "ID.plus",
     "Status",
     "Ocean")] = lapply(dd[c("ID", 
                             "Year",
                             "ID.plus",
                             "Status",
                             "Ocean")], as.factor)
```


For plotting reasons, entries refering to the position of a storm at a given time have to be transferred into a format that is easier to handle, i.e. numeric. For example, '28.0N' is becomming '28', and '94.8W' is transferred into '265.2'. Westward and soutward values are getting a negative sign, just like in an cartesian system. However, due to the fact that mapping is often far easier with positive values, both, 360 (degrees) is added to westward and eastward values. Hope that is comprehensible. 
```{r}
dd$Latitude[which(grepl("N", dd$Latitude)==TRUE)] <- as.numeric(gsub("N", "", dd$Latitude[which(grepl("N", dd$Latitude)==TRUE)]))
dd$Latitude[which(grepl("S", dd$Latitude)==TRUE)] <- -as.numeric(gsub("S", "", dd$Latitude[which(grepl("S", dd$Latitude)==TRUE)]))
dd$Longitude[which(grepl("W", dd$Longitude)==TRUE)] <- -as.numeric(gsub("W", "", dd$Longitude[which(grepl("W", dd$Longitude)==TRUE)])) + 360
dd$Longitude[which(grepl("E", dd$Longitude)==TRUE)] <- as.numeric(gsub("E", "", dd$Longitude[which(grepl("E", dd$Longitude)==TRUE)])) + 360
# Make both columns numeric.
dd$Latitude <- as.numeric(dd$Latitude)
dd$Longitude <- as.numeric(dd$Longitude)
```


Finally, as announced previuously, the duration of a storm is calculated.
```{r}
# ids <- as.character(unique(dd$ID))
for (i in as.character(unique(dd$ID))) {
  dd.i <- filter(dd, ID == i)
  for (n in 1:length(dd.i$ID)) {
    # '%--%' is the interval operator returning the time difference (lubridate).
    dd.i$Duration[n] <- as.numeric(as.duration(dd.i$DateTime.new[1] %--% dd.i$DateTime.new[n]))/60/60/24
  }
  dd$Duration[which(dd$ID %in% i)] <- dd.i$Duration
}
```

There you go! 
```{r echo = FALSE}
str(dd)
```


## First impression

I generate a new dataset that includes a couple of summary statistics such as minimum pressure or maximum duration for each **storm**...
```{r}
# Some summary statistics to see which was the strongest storm etc.
dd.sum <- dd %>%
  group_by(ID) %>%
  summarise(Name = unique(Name),
            ID.plus = unique(ID.plus),
            Year = first(Year),
            Min.Pressure = min(Minimum.Pressure, na.rm = TRUE),
            Max.Duration = max(Duration, na.rm = TRUE),
            Mean.Strength.kph = round(mean(Maximum.Wind.kph, 0)),
            Max.Strength.kph = max(Maximum.Wind.kph, na.rm = TRUE),
            Storm.Start = format(DateTime.new[1], "%d/%m %H:%M:%S"),
            Storm.Stop = format(DateTime.new[length(DateTime.new)], "%d/%m %H:%M:%S")) %>%
  arrange(-desc(Year))
str(dd.sum)
```

...and for each year. I use this dataset for mapping. You'll see this at a later point.
```{r}
dd.sum.year <- dd %>%
  group_by(Year) %>%
  summarise(DateTime.new = first(DateTime.new),
            # Date = first(DateTime.new[which(Minimum.Pressure == min(Minimum.Pressure, na.rm = TRUE))]),
            Min.Pressure = min(Minimum.Pressure, na.rm = TRUE),
            Max.Duration = max(Duration, na.rm = TRUE),
            Mean.Strength.kph = round(mean(Maximum.Wind.kph, 0)),
            Max.Strength.kph = max(Maximum.Wind.kph, na.rm = TRUE)) %>%
  arrange(-desc(Year))
```


But first, I have to assign the exact dates and times for these annual extreme values.
```{r}
# Get exact date and time for all extreme values!
p.min <- rep(NA, length(unique(dd$Year)))
d.max <- p.min
w.max <- p.min
for (i in 1:length(unique(dd$Year))) {
  p.min[i] = first(filter(dd, 
                          Year == unique(dd$Year)[i] & 
                            Minimum.Pressure == as.character(dd.sum.year$Min.Pressure[i]))$DateTime.new)
  d.max[i] = first(filter(dd, 
                          Year == unique(dd$Year)[i] & 
                            Duration == as.character(dd.sum.year$Max.Duration[i]))$DateTime.new)
  w.max[i] = first(filter(dd, 
                          Year == unique(dd$Year)[i] & 
                            Maximum.Wind.kph == as.character(dd.sum.year$Max.Strength.kph[i]))$DateTime.new)
}

dd.sum.year <- dd.sum.year %>%
  mutate(DateTime.p = as.POSIXct(p.min, origin = "1970-01-01")) %>%
  mutate(DateTime.d = as.POSIXct(d.max, origin = "1970-01-01")) %>%
  mutate(DateTime.w = as.POSIXct(w.max, origin = "1970-01-01"))
```


Then I make a couple of choices to get a nice ranking for a specific time period I would like to put my focus on.
```{r}
# The first 'n.select' storms are selected for highlightening.
n.select <- 10

# Longest duration (enire data set).
topn.Duration       <- arrange(dd.sum, desc(dd.sum$Max.Duration))[1:n.select,]
# Strongest wind speed recorded (entire data set)
topn.Strength.Max  <- arrange(dd.sum, desc(dd.sum$Max.Strength.kph))[1:n.select,]
# Minimum pressure (entire data set)
topn.Pressure.Min  <- arrange(dd.sum, -desc(dd.sum$Min.Pressure))[1:n.select,]
```


Let's have a look at these storms. First, I want to see which are the storms that lasted the longest. (I use a dataset called 'dd.s' indicating a selection of the entire summary data set 'dd.sum'.)
```{r}
dd.s <- topn.Duration

# Create an indicator for grouping.
groups = as.character(unique(dd.s$ID.plus))

# The basic map.
map = leaflet(dd.s) %>% 
  # addProviderTiles(providers$CartoDB.Positron)
  # addProviderTiles(providers$Esri.WorldTerrain)
  addProviderTiles(providers$CartoDB.DarkMatter)

# Colors of a specific palette assigned to 'Maximum.Wind'.
groupColors = colorNumeric(palette = "YlOrRd", domain = dd.s$Maximum.Wind.kph)

# Grouping!
for (g in groups) {
  d = dd[dd$ID.plus == g, ]
  map = map %>% 
    addPolylines(data = d,
                 color = "#788E95",
                 group = g,
                 lng = ~ Longitude,
                 lat = ~ Latitude,
                 weight = 0.6,
                 opacity = 0.6) %>%
    addCircleMarkers(data = d,
                     group = g,
                     lng = ~Longitude, 
                     lat = ~Latitude, 
                     color = ~groupColors(Maximum.Wind.kph),
                     weight = 2,
                     # fill = FALSE,
                     radius = ~(Maximum.Wind^1.2)/50,
                     # radius = ~sqrt(Maximum.Wind)*2,
                     popup = paste("Name: ", d$Name, "<br>",
                                   "Date: ", d$Date.new, "<br>",
                                   "Time: ", d$Time.new, "<br>",
                                   "Status: ", d$Status, "<br>",
                                   "Maximum wind speed: ", d$Maximum.Wind.kph, "km/h", "<br>"))
}

map %>%
  addLayersControl(overlayGroups = groups)
```


```{r}
dd.s %>%
  ggplot() +
  aes(x = DateTime.new,
      y = Minimum.Pressure
  ) +
  stat_density_2d(geom = "raster", 
                  aes(fill = ..density..), 
                  contour = FALSE,
                  alpha = 0.9,
                  show.legend = FALSE) +
  scale_fill_gradientn(colours = rev( brewer.pal( 9, "Greys" ))) +
  geom_point(alpha = 0.5,
             size = 0.3,
             colour = "#FBFBFA") +
  geom_smooth(method = "lm",
              se = FALSE,
              span = 0.2,
              colour = "#F93A2E",
              alpha = 0.9,
              size = 1.2) +
  geom_smooth(data = filter(dd.sum.year, year.min <= year(dd.sum.year$DateTime.p) & year(dd.sum.year$DateTime.p) <= year.max),
              aes(x = DateTime.p,
                  y = Min.Pressure),
              method = "lm",
              se = TRUE,
              span = 0.2,
              linetype = "dashed",
              colour = "#F93A2E",
              alpha = 0.9,
              size = 0.5) +
  geom_point(data = filter(dd.sum.year, year.min <= year(dd.sum.year$DateTime.p) & year(dd.sum.year$DateTime.p) <= year.max),
             aes(x = DateTime.p,
                 y = Min.Pressure),
             shape = 1,
             size = 1.2,
             stroke = 0.8,
             colour = "#F93A2E") +
  geom_line(data = filter(dd.sum.year, year.min <= year(dd.sum.year$DateTime.new) & year(dd.sum.year$DateTime.p) <= year.max),
            aes(x = (DateTime.p),
                y = Min.Pressure),
            size = 0.3,
            alpha = 0.9,
            colour = "#F93A2E") +
  theme_bw() +
  geom_rug(alpha = 0.025) +
  theme(panel.border = element_rect(colour = "black", fill = NA, size = 1)) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  labs(x = "Year", y = "Minimum Pressure (mbar)",
       title = "")
```





## Storing the data set

I am going to save the workspace and the data set for later use and exploration!
```{r}
save.image("Data/StormWS.RData")
write.csv(dd, file = "Data/StormDataset.csv")
write.csv(dd.sum, file = "Data/StormDatasetSummaryStats.csv")
```










## Loading the data set

```{r}
# Entire workspace.
source_data("https://github.com/thomassie/Storms/blob/master/Data/StormWS.RData?raw=true")
# Datasets.
dd <-  getURL("https://raw.githubusercontent.com/thomassie/Storms/master/Data/StormDataset.csv?token=AFYWCmhcgK3JQcnOB2gugWdbZ3Whd7_Nks5aXlK8wA%3D%3D")
dd <- read.csv(text = dd)
```











